{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "<h2> Análise das taxas de conversão sobre operações de crédito em dólar estadunidense</h2>\n",
    "<h3> Desenvolvido por Ana Letícia Souza </h3>\n",
    "<h4> Disponível em https://github.com/analetisouza/taxa_dolar_credito <h4>\n",
    "\n",
    "<p> Este trabalho objetiva realizar uma análise dos valores das taxas de conversão de dólar em compras internacionais efetuadas com cartão de crédito. Desta forma, visaremos ranquear os bancos examinando os valores por eles praticados, não apenas considerando as taxas de conversão mais baixas, mas também as menores taxas de variação, que podem ser mais vantajosas no longo prazo. As taxas de cotação de compra do dólar comercial também foram adicionadas com o intuito de serem um ponto de comparação. Os dados foram extraídos das APIs do Bradesco, da Caixa, do Itaú, do Nubank e do Banco Central do Brasil.</p>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<h3> Preparação Inicial </h3>\n",
    "\n",
    "<p>Importação das bibliotecas necessárias e gerenciamento de possíveis erros durante os acessos às APIs. </p>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import json\n",
    "import ssl \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n"
   ]
  },
  {
   "source": [
    "<h3> Captura dos Dados </h3>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_bradesco = \"https://proxy.api.prebanco.com.br/bradesco/dadosabertos/taxasCartoes/itens\"\n",
    "source_caixa = \"https://api.caixa.gov.br:8443/dadosabertos/taxasCartoes/1.2.0/itens\"\n",
    "source_itau = \"https://api.itau.com.br/dadosabertos/taxasCartoes/taxas/itens\"\n",
    "source_nubank = \"https://dadosabertos.nubank.com.br/taxasCartoes/itens\"\n",
    "source_cotacao = \"https://olinda.bcb.gov.br/olinda/servico/PTAX/versao/v1/odata/CotacaoDolarPeriodo(dataInicial=@dataInicial,dataFinalCotacao=@dataFinalCotacao)?@dataInicial='06%2F08%2F2020'&@dataFinalCotacao='10%2F18%2F2020'&$top=10000&$format=json&$select=cotacaoCompra,cotacaoVenda,dataHoraCotacao\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inicio_analise =  pd.to_datetime(\"2020-10-05\")\n",
    "periodo_analise = 30\n",
    "dias_excluidos = [\"2020-10-04\", \"2020-10-03\", \"2020-09-27\", \"2020-09-26\", \"2020-09-20\", \"2020-09-19\", \"2020-09-13\", \"2020-09-12\", \"2020-09-07\", \"2020-09-06\", \"2020-09-05\", \"2020-08-30\", \"2020-08-29\"]\n",
    "\n",
    "for i in range(len(dias_excluidos)):\n",
    "    dias_excluidos[i] = pd.to_datetime(dias_excluidos[i])"
   ]
  },
  {
   "source": [
    "<p>Aqui foram definidas algumas variáveis para nortear a análise. Durante o tratamento dos dados, percebi que alguns bancos atualizavam as informações todos os dias, enquanto outros atualizavam apenas nos dias úteis. Como possível solução, decidi que a melhor escolha seria remover os dias que não estavam presentes em todos os datasets, buscando deixá-los mais uniformes. A ideia inicial era utilizar uma API que fornecesse os finais de semana e feriados, de forma que permitisse que a exploração dos dados fosse mais flexível. Como não consegui encontrar nenhuma gratuita, inseri os dados manualmente referente ao período de 30 dias que estipulei para este estudo. </p>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepara_dataframe(source):\n",
    "\n",
    "    df_linha = pd.DataFrame()\n",
    "\n",
    "    if source == source_itau: \n",
    "        df_source = json.loads(requests.get(source_itau).text)\n",
    "        df_source = pd.DataFrame(df_source[0])\n",
    "        df_source = df_source.at[0, 'itens']\n",
    "        df_emissor = pd.DataFrame(df_source['emissor'], index = [0])\n",
    "        df_historico = pd.DataFrame(df_source['historicoTaxas'])\n",
    "\n",
    "        for linha in range(df_historico.shape[0]):\n",
    "            df_linha = pd.concat([df_linha, df_emissor], ignore_index = True)\n",
    "            df_historico['taxaData'] = pd.to_datetime(df_historico['taxaData'])\n",
    "            df_source = df_linha\n",
    "\n",
    "        df_source = pd.concat([df_source, df_historico], axis = 1)\n",
    "        df_source = df_source.drop(columns = ['emissorCnpj', 'taxaDivulgacaoDataHora'])\n",
    "\n",
    "    elif source == source_cotacao:\n",
    "        df_source = pd.read_json(source)\n",
    "        hist_source = df_source.iloc[:,[1]]\n",
    "        df_historico = pd.DataFrame()\n",
    "\n",
    "        for linha in range(hist_source.shape[0]):\n",
    "            df_linha = pd.DataFrame(hist_source.at[linha,'value'], index = [0])\n",
    "            df_linha['dataHoraCotacao'] = pd.to_datetime(df_linha['dataHoraCotacao']).dt.date\n",
    "            df_historico = pd.concat([df_historico, df_linha], ignore_index = True)\n",
    "            df_source = df_historico\n",
    "\n",
    "    else:\n",
    "        df_source = pd.read_json(source)\n",
    "        hist_source = df_source.iloc[:,[2]]\n",
    "        df_historico = pd.DataFrame()\n",
    "\n",
    "        for linha in range(hist_source.shape[0]):\n",
    "            df_linha = pd.DataFrame(hist_source.at[linha,'historicoTaxas'], index = [0])\n",
    "            df_linha['taxaData'] = pd.to_datetime(df_linha['taxaData'])\n",
    "            df_historico = pd.concat([df_historico, df_linha], ignore_index = True)\n",
    "\n",
    "        df_source = pd.concat([df_source, df_historico], axis = 1)\n",
    "        df_source = df_source.drop(columns = ['emissorCnpj', 'historicoTaxas', 'taxaDivulgacaoDataHora'])\n",
    "    return df_source"
   ]
  },
  {
   "source": [
    "<p> Essa função é responsável por ler os dados json retirado das APIs e organizá-los em dataframes. Nesse primeiro momento, os dados de cada banco têm seu dataframe individual.</p>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bradesco = prepara_dataframe(source_bradesco)\n",
    "df_caixa = prepara_dataframe(source_caixa)\n",
    "df_itau = prepara_dataframe(source_itau)\n",
    "df_nubank = prepara_dataframe(source_nubank)\n",
    "df_cotacao = prepara_dataframe(source_cotacao)"
   ]
  },
  {
   "source": [
    "<h3> Limpeza dos Dados </h3>\n",
    "\n",
    "<p> Aqui os dados já foram organizados em dataframes mas precisam ser refinados para que sigam o mesmo padrão. </p>\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def altera_data_inicio(df, df_data, inicio):\n",
    "\n",
    "    for linha in range(df.shape[0]):\n",
    "\n",
    "        if df_data[linha] == inicio:\n",
    "            return df\n",
    "\n",
    "        else:\n",
    "            df = df.drop(linha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def altera_dias_uteis(df, df_data):\n",
    "\n",
    "    quantidade_dias = len(dias_excluidos)\n",
    "    linha = 0\n",
    "\n",
    "    for contador in range(quantidade_dias):\n",
    "\n",
    "        while not df_data[linha] == dias_excluidos[contador]:\n",
    "            linha = linha + 1\n",
    "\n",
    "        df = df.drop(linha)\n",
    "        linha = linha + 1\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "source": [
    "<p> A primeira etapa é remover os dados referentes à operações de débito do Banco Bradesco, pois estamos trabalhando apenas com crédito. Logo em seguida, invertemos a ordem do dataset, para que comece pela data mais recente, assim como os demais. </p>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bradesco = df_bradesco.drop(df_bradesco.loc[df_bradesco['taxaTipoGasto'] == 'Débito à conta'].index)\n",
    "df_bradesco = df_bradesco.iloc[::-1].reset_index(drop = True)\n",
    "df_cotacao = df_cotacao.iloc[::-1].reset_index(drop = True)\n"
   ]
  },
  {
   "source": [
    "<p> Após, mantemos apenas os dias úteis nos datasets que incluem fins de semana e feriados. </p>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_itau = altera_dias_uteis(df_itau, df_itau[\"taxaData\"])\n",
    "df_nubank = altera_dias_uteis(df_nubank, df_nubank[\"taxaData\"])"
   ]
  },
  {
   "source": [
    "<p> Como alguns bancos atualizam seus dados antes que outros, pode ocorrer que a data mais recente de um não esteja disponível ainda no outro. Sendo assim, escolhi uma data que estivesse presente em todos e defini como ponto de partida, removendo as anteriores à ela. </p>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bradesco = altera_data_inicio(df_bradesco, df_bradesco[\"taxaData\"], inicio_analise)\n",
    "df_caixa = altera_data_inicio(df_caixa, df_caixa[\"taxaData\"], inicio_analise)\n",
    "df_itau = altera_data_inicio(df_itau, df_itau[\"taxaData\"], inicio_analise)\n",
    "df_nubank = altera_data_inicio(df_nubank, df_nubank[\"taxaData\"], inicio_analise)\n",
    "df_cotacao = altera_data_inicio(df_cotacao, df_cotacao[\"dataHoraCotacao\"], inicio_analise)"
   ]
  },
  {
   "source": [
    "<p>Neste ponto as alterações realizadas anteriormente desorganizaram a indexação do dataframe. Por isso, realizaremos as operações abaixo para reestabecê-la em cada dataframe. </p>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bradesco = df_bradesco.reset_index(drop = True)\n",
    "df_caixa = df_caixa.reset_index(drop = True)\n",
    "df_itau = df_itau.reset_index(drop = True)\n",
    "df_nubank = df_nubank.reset_index(drop = True)\n",
    "df_cotacao = df_cotacao.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_caixa = df_caixa.replace({'CAIXA ECONOMICA FEDERAL' : 'Caixa Economica Federal', 'CREDITO' : 'Crédito'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bradesco = df_bradesco.loc[:29]\n",
    "df_caixa = df_caixa.loc[:29]\n",
    "df_itau = df_itau.loc[:29]\n",
    "df_nubank = df_nubank.loc[:29]\n",
    "df_cotacao = df_cotacao.loc[:29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analise = pd.DataFrame()\n",
    "df_analise.insert(0, 'Data', df_cotacao[\"dataHoraCotacao\"])\n",
    "df_analise.insert(1, 'Compra', df_cotacao[\"cotacaoCompra\"])\n",
    "df_analise.insert(2, 'Bradesco', df_bradesco[\"taxaConversao\"])\n",
    "df_analise.insert(3, 'Caixa', df_caixa[\"taxaConversao\"])\n",
    "df_analise.insert(4, 'Itaú', df_itau[\"taxaConversao\"])\n",
    "df_analise.insert(5, 'Nubank', df_nubank[\"taxaConversao\"])"
   ]
  },
  {
   "source": [
    "<h3> Análise dos Dados </h3>\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         Compra   Bradesco      Caixa       Itaú     Nubank\n",
       "count  30.00000  30.000000  30.000000  30.000000  30.000000\n",
       "mean    5.45298   5.742333   5.681667   5.752000   5.671727\n",
       "std     0.14541   0.152918   0.147589   0.153317   0.151235\n",
       "min     5.25260   5.530000   5.458000   5.540000   5.463300\n",
       "25%     5.29880   5.580000   5.534625   5.590000   5.511350\n",
       "50%     5.45535   5.745000   5.674750   5.755000   5.674200\n",
       "75%     5.59240   5.887500   5.821000   5.897500   5.816700\n",
       "max     5.65210   5.950000   5.874500   5.960000   5.878900"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Compra</th>\n      <th>Bradesco</th>\n      <th>Caixa</th>\n      <th>Itaú</th>\n      <th>Nubank</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>30.00000</td>\n      <td>30.000000</td>\n      <td>30.000000</td>\n      <td>30.000000</td>\n      <td>30.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>5.45298</td>\n      <td>5.742333</td>\n      <td>5.681667</td>\n      <td>5.752000</td>\n      <td>5.671727</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.14541</td>\n      <td>0.152918</td>\n      <td>0.147589</td>\n      <td>0.153317</td>\n      <td>0.151235</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>5.25260</td>\n      <td>5.530000</td>\n      <td>5.458000</td>\n      <td>5.540000</td>\n      <td>5.463300</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>5.29880</td>\n      <td>5.580000</td>\n      <td>5.534625</td>\n      <td>5.590000</td>\n      <td>5.511350</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>5.45535</td>\n      <td>5.745000</td>\n      <td>5.674750</td>\n      <td>5.755000</td>\n      <td>5.674200</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>5.59240</td>\n      <td>5.887500</td>\n      <td>5.821000</td>\n      <td>5.897500</td>\n      <td>5.816700</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>5.65210</td>\n      <td>5.950000</td>\n      <td>5.874500</td>\n      <td>5.960000</td>\n      <td>5.878900</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "df_analise.describe()"
   ]
  }
 ]
}