{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "<h2> Análise das taxas de conversão sobre operações de crédito em dólar estadunidense</h2>\n",
    "<h3> Desenvolvido por Ana Letícia Souza </h3>\n",
    "<h4> Disponível em https://github.com/analetisouza/taxa_dolar_credito <h4>\n",
    "\n",
    "<p> Este trabalho objetiva realizar uma análise dos valores das taxas de conversão de dólar em compras internacionais efetuadas com cartão de crédito. Desta forma, visaremos ranquear os bancos examinando os valores por eles praticados, não apenas considerando as taxas de conversão mais baixas, mas também as menores taxas de variação, que podem ser mais vantajosas no longo prazo. As taxas de cotação de compra do dólar comercial também foram adicionadas com o intuito de serem um ponto de comparação. Os dados foram extraídos das APIs do Bradesco, da Caixa, do Itaú, do Nubank e do Banco Central do Brasil.</p>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<h3> Preparação Inicial </h3>\n",
    "\n",
    "<p>Importação das bibliotecas necessárias e gerenciamento de possíveis erros durante os acessos às APIs. </p>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas            as pd\n",
    "import numpy             as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import json\n",
    "import ssl \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n"
   ]
  },
  {
   "source": [
    "<h3> Captura dos Dados </h3>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_bradesco = \"https://proxy.api.prebanco.com.br/bradesco/dadosabertos/taxasCartoes/itens\"\n",
    "source_caixa = \"https://api.caixa.gov.br:8443/dadosabertos/taxasCartoes/1.2.0/itens\"\n",
    "source_itau = \"https://api.itau.com.br/dadosabertos/taxasCartoes/taxas/itens\"\n",
    "source_nubank = \"https://dadosabertos.nubank.com.br/taxasCartoes/itens\"\n",
    "source_cotacao = \"https://olinda.bcb.gov.br/olinda/servico/PTAX/versao/v1/odata/CotacaoDolarPeriodo(dataInicial=@dataInicial,dataFinalCotacao=@dataFinalCotacao)?@dataInicial='06%2F08%2F2020'&@dataFinalCotacao='10%2F18%2F2020'&$top=10000&$format=json&$select=cotacaoCompra,cotacaoVenda,dataHoraCotacao\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inicio_analise =  pd.to_datetime(\"2020-10-05\")\n",
    "periodo_analise = 30\n",
    "dias_excluidos = [\"2020-10-04\", \"2020-10-03\", \"2020-09-27\", \"2020-09-26\", \"2020-09-20\", \"2020-09-19\", \"2020-09-13\", \"2020-09-12\", \"2020-09-07\", \"2020-09-06\", \"2020-09-05\", \"2020-08-30\", \"2020-08-29\"]\n",
    "\n",
    "for i in range(len(dias_excluidos)):\n",
    "    dias_excluidos[i] = pd.to_datetime(dias_excluidos[i])"
   ]
  },
  {
   "source": [
    "<p>Aqui foram definidas algumas variáveis para nortear a análise. Durante o tratamento dos dados, percebi que alguns bancos atualizavam as informações todos os dias, enquanto outros atualizavam apenas nos dias úteis. Como possível solução, decidi que a melhor escolha seria remover os dias que não estavam presentes em todos os datasets, buscando deixá-los mais uniformes. A ideia inicial era utilizar uma API que fornecesse os finais de semana e feriados, de forma que permitisse que a exploração dos dados fosse mais flexível. Como não consegui encontrar nenhuma gratuita, inseri os dados manualmente referente ao período de 30 dias que estipulei para este estudo. </p>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepara_dataframe(source):\n",
    "\n",
    "    df_linha = pd.DataFrame()\n",
    "\n",
    "    if source == source_itau: \n",
    "        df_source = json.loads(requests.get(source_itau).text)\n",
    "        df_source = pd.DataFrame(df_source[0])\n",
    "        df_source = df_source.at[0, 'itens']\n",
    "        df_emissor = pd.DataFrame(df_source['emissor'], index = [0])\n",
    "        df_historico = pd.DataFrame(df_source['historicoTaxas'])\n",
    "\n",
    "        for linha in range(df_historico.shape[0]):\n",
    "            df_linha = pd.concat([df_linha, df_emissor], ignore_index = True)\n",
    "            df_historico['taxaData'] = pd.to_datetime(df_historico['taxaData'])\n",
    "            df_source = df_linha\n",
    "\n",
    "        df_source = pd.concat([df_source, df_historico], axis = 1)\n",
    "        df_source = df_source.drop(columns = ['emissorCnpj', 'taxaDivulgacaoDataHora'])\n",
    "\n",
    "    elif source == source_cotacao:\n",
    "        df_source = pd.read_json(source)\n",
    "        hist_source = df_source.iloc[:,[1]]\n",
    "        df_historico = pd.DataFrame()\n",
    "\n",
    "        for linha in range(hist_source.shape[0]):\n",
    "            df_linha = pd.DataFrame(hist_source.at[linha,'value'], index = [0])\n",
    "            df_linha['dataHoraCotacao'] = pd.to_datetime(df_linha['dataHoraCotacao']).dt.date\n",
    "            df_historico = pd.concat([df_historico, df_linha], ignore_index = True)\n",
    "            df_source = df_historico\n",
    "\n",
    "    else:\n",
    "        df_source = pd.read_json(source)\n",
    "        hist_source = df_source.iloc[:,[2]]\n",
    "        df_historico = pd.DataFrame()\n",
    "\n",
    "        for linha in range(hist_source.shape[0]):\n",
    "            df_linha = pd.DataFrame(hist_source.at[linha,'historicoTaxas'], index = [0])\n",
    "            df_linha['taxaData'] = pd.to_datetime(df_linha['taxaData'])\n",
    "            df_historico = pd.concat([df_historico, df_linha], ignore_index = True)\n",
    "\n",
    "        df_source = pd.concat([df_source, df_historico], axis = 1)\n",
    "        df_source = df_source.drop(columns = ['emissorCnpj', 'historicoTaxas', 'taxaDivulgacaoDataHora'])\n",
    "    return df_source"
   ]
  },
  {
   "source": [
    "<p> Essa função é responsável por ler os dados json retirado das APIs e organizá-los em dataframes. Nesse primeiro momento, os dados de cada banco têm seu dataframe individual.</p>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bradesco = prepara_dataframe(source_bradesco)\n",
    "df_caixa = prepara_dataframe(source_caixa)\n",
    "df_itau = prepara_dataframe(source_itau)\n",
    "df_nubank = prepara_dataframe(source_nubank)\n",
    "df_cotacao = prepara_dataframe(source_cotacao)"
   ]
  },
  {
   "source": [
    "<h3> Limpeza dos Dados </h3>\n",
    "\n",
    "<p> Aqui os dados já foram organizados em dataframes mas precisam ser refinados para que sigam o mesmo padrão. </p>\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def altera_data_inicio(df, df_data, inicio):\n",
    "\n",
    "    for linha in range(df.shape[0]):\n",
    "\n",
    "        if df_data[linha] == inicio:\n",
    "            return df\n",
    "\n",
    "        else:\n",
    "            df = df.drop(linha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def altera_dias_uteis(df, df_data):\n",
    "\n",
    "    quantidade_dias = len(dias_excluidos)\n",
    "    linha = 0\n",
    "\n",
    "    for contador in range(quantidade_dias):\n",
    "\n",
    "        while not df_data[linha] == dias_excluidos[contador]:\n",
    "            linha = linha + 1\n",
    "\n",
    "        df = df.drop(linha)\n",
    "        linha = linha + 1\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "source": [
    "<p> A primeira etapa é remover os dados referentes à operações de débito do Banco Bradesco, pois estamos trabalhando apenas com crédito. Logo em seguida, invertemos a ordem do dataset, para que comece pela data mais recente, assim como os demais. </p>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bradesco = df_bradesco.drop(df_bradesco.loc[df_bradesco['taxaTipoGasto'] == 'Débito à conta'].index)\n",
    "df_bradesco = df_bradesco.iloc[::-1].reset_index(drop = True)\n",
    "df_cotacao = df_cotacao.iloc[::-1].reset_index(drop = True)\n"
   ]
  },
  {
   "source": [
    "<p> Após, mantemos apenas os dias úteis nos datasets que incluem fins de semana e feriados. </p>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_itau = altera_dias_uteis(df_itau, df_itau[\"taxaData\"])\n",
    "df_nubank = altera_dias_uteis(df_nubank, df_nubank[\"taxaData\"])"
   ]
  },
  {
   "source": [
    "<p> Como alguns bancos atualizam seus dados antes que outros, pode ocorrer que a data mais recente de um não esteja disponível ainda no outro. Sendo assim, escolhi uma data que estivesse presente em todos e defini como ponto de partida, removendo as anteriores à ela. </p>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bradesco = altera_data_inicio(df_bradesco, df_bradesco[\"taxaData\"], inicio_analise)\n",
    "df_caixa = altera_data_inicio(df_caixa, df_caixa[\"taxaData\"], inicio_analise)\n",
    "df_itau = altera_data_inicio(df_itau, df_itau[\"taxaData\"], inicio_analise)\n",
    "df_nubank = altera_data_inicio(df_nubank, df_nubank[\"taxaData\"], inicio_analise)\n",
    "df_cotacao = altera_data_inicio(df_cotacao, df_cotacao[\"dataHoraCotacao\"], inicio_analise)"
   ]
  },
  {
   "source": [
    "<p>Neste ponto as alterações realizadas anteriormente desorganizaram a indexação do dataframe. Por isso, realizaremos as operações abaixo para reestabecê-la em cada dataframe. </p>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bradesco = df_bradesco.reset_index(drop = True)\n",
    "df_caixa = df_caixa.reset_index(drop = True)\n",
    "df_itau = df_itau.reset_index(drop = True)\n",
    "df_nubank = df_nubank.reset_index(drop = True)\n",
    "df_cotacao = df_cotacao.reset_index(drop = True)"
   ]
  },
  {
   "source": [
    "<p>O comando seguinte substitui alguns dados do dataset da Caixa, novamente com o intuito de seguir a mesma linha que os demais. </p>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_caixa = df_caixa.replace({'CAIXA ECONOMICA FEDERAL' : 'Caixa Economica Federal', 'CREDITO' : 'Crédito'})\n"
   ]
  },
  {
   "source": [
    "<p>Levando em consideração que os datasets abrangem períodos diferentes e para tornar os dados mais enxutos, todos os dataframes foram reduzidos para os últimos 30 dias úteis. </p>\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bradesco = df_bradesco.loc[:29]\n",
    "df_caixa = df_caixa.loc[:29]\n",
    "df_itau = df_itau.loc[:29]\n",
    "df_nubank = df_nubank.loc[:29]\n",
    "df_cotacao = df_cotacao.loc[:29]"
   ]
  },
  {
   "source": [
    "<p>Para facilitar a apuração dos dados, as infromações mais importantes de cada dataframe foram extraídas e reunidas em um único dataframe geral.</p>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analise = pd.DataFrame()\n",
    "df_analise.insert(0, 'Data', df_cotacao[\"dataHoraCotacao\"])\n",
    "df_analise.insert(1, 'Compra', df_cotacao[\"cotacaoCompra\"])\n",
    "df_analise.insert(2, 'Bradesco', df_bradesco[\"taxaConversao\"])\n",
    "df_analise.insert(3, 'Caixa', df_caixa[\"taxaConversao\"])\n",
    "df_analise.insert(4, 'Itaú', df_itau[\"taxaConversao\"])\n",
    "df_analise.insert(5, 'Nubank', df_nubank[\"taxaConversao\"])"
   ]
  },
  {
   "source": [
    "<h3> Análise dos Dados </h3>\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "          Data  Compra  Bradesco   Caixa  Itaú  Nubank\n0   2020-10-05  5.6293      5.93  5.8495  5.94  5.8551\n1   2020-10-02  5.6458      5.95  5.8675  5.96  5.8723\n2   2020-10-01  5.6435      5.94  5.8640  5.95  5.8699\n3   2020-09-30  5.6401      5.94  5.8745  5.95  5.8663\n4   2020-09-29  5.6521      5.95  5.8675  5.96  5.8789\n5   2020-09-28  5.5852      5.88  5.8600  5.89  5.8092\n6   2020-09-25  5.5661      5.86  5.7835  5.87  5.7894\n7   2020-09-24  5.5708      5.87  5.7885  5.88  5.7943\n8   2020-09-23  5.5305      5.82  5.7925  5.83  5.7523\n9   2020-09-22  5.4323      5.72  5.6745  5.73  5.6502\n10  2020-09-21  5.4434      5.73  5.6560  5.74  5.6618\n11  2020-09-18  5.2883      5.57  5.5805  5.58  5.5005\n12  2020-09-17  5.2587      5.54  5.4750  5.55  5.4697\n13  2020-09-16  5.2526      5.53  5.4580  5.54  5.4633\n14  2020-09-15  5.2722      5.55  5.4965  5.56  5.4837\n15  2020-09-14  5.2978      5.58  5.5090  5.59  5.5103\n16  2020-09-11  5.2848      5.57  5.5500  5.58  5.4968\n17  2020-09-10  5.2930      5.57  5.5295  5.58  5.5053\n18  2020-09-09  5.3018      5.58  5.5080  5.59  5.5145\n19  2020-09-08  5.3692      5.65  5.5795  5.66  5.5846\n20  2020-09-04  5.2842      5.57  5.5290  5.57  5.4962\n21  2020-09-03  5.3073      5.59  5.5150  5.60  5.5202\n22  2020-09-02  5.3735      5.66  5.5840  5.67  5.5891\n23  2020-09-01  5.3726      5.66  5.6015  5.67  5.5881\n24  2020-08-31  5.4707      5.76  5.6850  5.77  5.6902\n25  2020-08-28  5.4673      5.76  5.6750  5.77  5.6866\n26  2020-08-27  5.5950      5.89  5.8085  5.90  5.8194\n27  2020-08-26  5.5674      5.86  5.8500  5.87  5.7907\n28  2020-08-25  5.5991      5.90  5.8230  5.91  5.8237\n29  2020-08-24  5.5948      5.89  5.8150  5.90  5.8192\n"
     ]
    }
   ],
   "source": [
    "print(df_analise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         Compra   Bradesco      Caixa       Itaú     Nubank\n",
       "count  30.00000  30.000000  30.000000  30.000000  30.000000\n",
       "mean    5.45298   5.742333   5.681667   5.752000   5.671727\n",
       "std     0.14541   0.152918   0.147589   0.153317   0.151235\n",
       "min     5.25260   5.530000   5.458000   5.540000   5.463300\n",
       "25%     5.29880   5.580000   5.534625   5.590000   5.511350\n",
       "50%     5.45535   5.745000   5.674750   5.755000   5.674200\n",
       "75%     5.59240   5.887500   5.821000   5.897500   5.816700\n",
       "max     5.65210   5.950000   5.874500   5.960000   5.878900"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Compra</th>\n      <th>Bradesco</th>\n      <th>Caixa</th>\n      <th>Itaú</th>\n      <th>Nubank</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>30.00000</td>\n      <td>30.000000</td>\n      <td>30.000000</td>\n      <td>30.000000</td>\n      <td>30.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>5.45298</td>\n      <td>5.742333</td>\n      <td>5.681667</td>\n      <td>5.752000</td>\n      <td>5.671727</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.14541</td>\n      <td>0.152918</td>\n      <td>0.147589</td>\n      <td>0.153317</td>\n      <td>0.151235</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>5.25260</td>\n      <td>5.530000</td>\n      <td>5.458000</td>\n      <td>5.540000</td>\n      <td>5.463300</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>5.29880</td>\n      <td>5.580000</td>\n      <td>5.534625</td>\n      <td>5.590000</td>\n      <td>5.511350</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>5.45535</td>\n      <td>5.745000</td>\n      <td>5.674750</td>\n      <td>5.755000</td>\n      <td>5.674200</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>5.59240</td>\n      <td>5.887500</td>\n      <td>5.821000</td>\n      <td>5.897500</td>\n      <td>5.816700</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>5.65210</td>\n      <td>5.950000</td>\n      <td>5.874500</td>\n      <td>5.960000</td>\n      <td>5.878900</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "df_analise.describe()"
   ]
  }
 ]
}